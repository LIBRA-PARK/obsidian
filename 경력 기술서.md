# 인터페이스 리소스 및 거래 관리 및 배포 통합 API 개발
(주)TmaxSoft, Interface Core 파트 - 연구원
2024.07 ~ 진행 중

## 설계 목적
현 프레임워크 'AnyLink 7'은 인터페이스 운영하기 위한 세션(Adapter, Endpoint 등)과 BPMN 정의(Transaction, Flow)하고 실제로 실행되는 Engine에 리소스를 배포해야하며, 본 과정은 세션을 정의하는 Admin Web Application 과 BPMN 정의하기 위해 이용되는 Ecplipse IDE Applciation 총 2개의 Application 통해서 수행된다.

![[Pasted image 20240906190434.png]]

상이한 Web과 Eclipse IDE 환경은 편의과 이슈 대응 속도 저하를 유발 하는데, 두 환경에 대한 리소스가 공유되지 않기에 빈번한 Application 이동이 발생하고 확인 해야한다. 그리고 Web Application의 경우에는 데이터베이스에 Eclipse IDE Application은 로컬 폴더에 리소스가 정장 되어 Engine 에서 실행되기 전 까지 유효성을 검사할 수 없다. 이 구조로 운영 지원 파트는 사이트에 대한 운영을 위해서 두 Application 빈번한 체크 과정이 필요하고, 때문에 인터페이스를 실행하기 위한 흐름이 증가한다. 또한, 배포되어 실행되기 전 까지 인터페이스에 대한 유효성을 판단할 수 없기 때문에 온전히 담당자에 의해서 결과가 결정된다. 이 결과로 휴먼 에러가 발생될 확률이 높아지고 이슈가 발생될 경우 세션 또는 BPMN 정의의 문제인지 아니면 배포 상 오류 인지 트러블 영역을 판단할 수 없어 개발 팀에서는 대응을 위해서는 이슈 상황과 동일한 인터페이스를 배포한 후 통합 디버깅을 진행하는 불편함을 겪어야했다.
## 문제 정의
+ 작업 흐름의 비효율성
	+ 정상적인 프레임워크 이용을 위해 Web 과 Eclipse IDE Application 간 빈번한 이동이 필요하다는 점
+ 휴먼 에러 발생 가능성 증가
	+ 서로 상이한 환경의 Application 에서 리소스 공유하지 못해 배포 전까지 유효성 검사가 진행되지 못해 담당자가 모두 수동으로 검사를 진행함
+ 이슈 분석 및 대응 속도 증가
	+ 문제가 발생될 경우 세션, BPMN 정의 인지 배포 상 문제가 발생한 것이지 판단하기 어려워 이슈 대응에 시간이 많이 소요되고 원인 분석을 위해 통합 디버깅 과정 강제됨

## 해결 과정
본 문제점들을 해결하기 Eclipse IDE Application에서 이용되는 리소스(Transaction, Message 등)를 동일한 데이터베이스에 저장했다. 이 리소스는 세션과 동일하게 계층적 구조로 데이터베이스에 쉽게 추가됬다. 다만 XML 파일 형식의 데이터를 가지는 BPMN Flow 의 경우에는 그 형식을 스키마로 정의할 수 없어 BLOB Column 형식을 사용해 Key-Value 저장 방식을 채용해 저장했다. 이로써 동일한 환경에서 데이터를 공유하기에 'Outbound Rule' 같이 세션의 리소스(Endpoint)를 참조해 정의되는 리소스를 저장하기 전에 유효성 체크를 진행으로 리소스 저장에서 발생될 수 있는 휴먼 에러를 방지할 수 있었다.

그리고 Eclipse IDE Application 의 주된 기능인 배포를 API로 개발해 통합 API 서버를 개발하여 작업 흐름의 비효율성을 줄이고자 했다. 이를 위해서 배포 서비스가 호출 전 이벤트와 기능들을 분석과 역할을 세분화해서 파악했고, 배포 전 엔진에서 동작할 수 있는 상태로 리소스를 변환(.java) 및 컴파일(.class) 하는 과정이 프레임워크에서 인터페이스를 동작하기 위한 필수다.

![[Pasted image 20240910122928.png]]

+ Code generation (FreeMarker)
	+ XML로 저장된 리소스를 Java 컴파일을 진행할 수 있도록 .java 파일로 변환
+ Java Compile (javax.tools.JavaCompiler)
	+ 변환된 .java 파일에 컴파일을 통해서 .class 파일 생성

위 과정을 거쳐서 생성된 .class 파일의 집합을 Interface Execute Engine 전송해 ClassLoader 에 Class 를 적재시켜 Engine에 들어오는 요청을 정의된 인터페이스로 실행하게 되는 것이다. 따라서, 본 두 과정을 서비스로 구현해 통합 API서버에 Deploy API의 서비스로 이식했다. 구현된 API는 기능 테스트를 진행해 정상적으로 'Code generation' 과정과 'Java Complie' 과정을 거쳐서 최종적으로 Engine에서 동작할 수 있는 파일 집합을 구성할 수 있었다.

하지만, 다중 배포 API와 규모가 큰 인터페이스에 대해서 구현된 API를 호출할 경우 Code-generation 이며 Complie 의 서비스 실행 시간이 길어지기 때문에 API 의 타임아웃을 초래했다. 타임아웃 기준을 늘리는 것은 해당 요청이 Error 인해서 멈추었는지 실행 중인지 판단할 수 없기 때문에 오히려 편의성 측면에서 방해가 되며, 늘리는 것은 본 문제를 본질적으로 해결한 것이기 아니기 때문에 다른 방안으로 구현했다.

배포 전에 발생되는 이벤트를 비동기 이벤트 처리 방식과 MSA 구조로 설계해 별도의 Application으로 처리될 수 있도록 변경해, Deploy API 호출을 즉각적인 응답이 아닌 비동기 이벤트 명령을 전달하는 API로 변경했다. 사용자는 배포 결과 대한 정보를 즉각적인 응답으로 받을 순 없으나, 별도의 조회 API를 이용해서 결과 및 현황에 대한 정보를 제공 받을 수 있도록 변경했다.

![[Pasted image 20240910133720.png]]
+ Compile Application 
	+ 생성된 .java 파일에 대해서 Complie을 진행해 .class 파일을 생성
+ Code-gen Application
	+ 배포 요청된 Transaction에 사용되는 리소스를 데이터베이스로 조회 후 로컬 폴더에 .java 파일을 생성
+ Deploy Application
	+ 생성된 .class 파일을 하나의 압축하여 지정한 Interface Execute Engine 정보를 데이터베이스로 조회한 후 해당 주소로 리소스 전송
+ Error Application
	+ 모든 Application에서 Exception 또는 에러가 발생 될 경우 Error Message를 Queue에 추가해 그 뒤의 롤백 로직을 Error Application에서 진행될 수 있도록 설계했다. 따라서 본 Error Application은 에러나 예외에 대한 케이스 별로 해당되는 롤백 로직을 수행

배포 API로 시작되는 이벤트에 대한 상태 추적과 예외 관련된 정보를 조회하기 위해서 데이터베이스에 Transaction 과 Trace 테이블을 생성 후 Transaction 과 Trace 가 1:N 관계를 가지도록 코드 레벨에서 구현했다. 그리고 Deploy API 호출 시 UUID를 통해서 ID를 발급 받고 Transaction 테이블로 INSERT하고 Message Queue Header 활용해 각 Application에서 발급 받은 Transaction ID를 기반으로 이벤트 처리된 결과 및 예외를 Trace 테이블에 INSERT 구조로 구현했다.

## 결과
통합 API 서버 개발로 리소스가 공유되지 못하던 문제와 배포 프로세스의 대한 작업 흐름 비효율성을 개선하고 유효성을 체크를 보장하여 휴먼 에러를 감소 시킬 수 있도록 개선하게 되었다. 개선되는 새로이 발생한 API 타임 아웃 문제에 직면했을 때는 프로젝트의 구조르 MSA 구조로 변경하고 API에 대해서 비동기 이벤트 처리 방식으로 개선하여 해결했다. 

+ 인터페이스 에디터 API 개발
+ 통합 환경을 제공하게 되면서 운영 환경에 대한 전체 유효성 체크와 흐름도 파악 가능한 API 개발됨
+ 싱글 애플리케이션 구조 멀티 모듈 프로젝트 구조 설계

새로 개발된 통합 API 서비스는 새로운 구조 방식으로 성능 개선과 사용 편의성 측면에서 개선 되었으며,  동일한 환경에서 세션과 BPMN 정의와 유효성 검사를 가능하게 해 더 효율적이며 안정적인 작업을 제공함

# Kubernetes 테스트베드 자동 구축 API 서버 개발
(주)TmaxSoft, Interface Core 파트 - 연구원
2024.06 ~ 진행 중
## 설계 목적
인터페이스 프레임워크는 사이트 별 데이터베이스, JDK 버전 등 운영되는 환경이 상이하게 달라서 이슈가 발생될 경우 대응할 수 있도록 동일한 환경이 필요하다. 그리고 B2B 특성상 주기적인 업데이트가 존재하지 않고 운영 사이트 별로 배포된 Build 버전이 상이함. 이에 따라서 이슈가 발생할 경우 Build 버전을 고려해 동일한 환경을 구축해서 이슈에 대한 분석을 진행해야 한다.


![[Pasted image 20240910151249.png]]


이슈를 분석하기 위해선 이슈가 발생한 인터페이스를 다운로드 후 동일한 환경에 인터페이스를 배포하여 해당 이슈를 재현한다. 이슈 분석에도 통합 디버깅이다 보니 오랜 시간이 소요되는데 이슈 도중 다른 이슈에 대한 추가 검증이나 분석 요청 또는 긴급 이슈로 분석 환경이 변경되는 경우가 발생하게 되면 다시 환경을 변경하는 번거로운 과정이 발생한다. 

이슈에 대한 보고는 운영 파트에서 고객의 사이트 환경에서 발생된 이슈를 환경과 함께 보고한다. 그리고 리포트된 이슈를 1차적으로 QA 파트에서 검증한 후 재연된 시나리오를 전달해주어 이슈가 대응되는 프로세스이다. 하지만 여기서 대두되는 문제는 인터페이스에 대한 이슈 불일치 현상으로, 운영, QA 그리고 개발 파트 간 재연이 불일치하는 현상이 발생할 수 있는데, 이럴 경우 원인에 대해서 상정할 수 없어 이슈 대응 시간이 기하급수적으로 증가한다.

이 불일치 현상은 운영 사이트와 QA 파트와 개발 파트 간 분석하는 환경이 상이해서 발생된다. 인터페이스 프레임워크는 JDK와 데이터베이스 심지어는 배포된 인터페이스나 정의된 세션에 정보에 따라서 인터페이스의 결과가 다르게 나올 수 있다. 따라서 각 파트는 최대한 환경에 대한 정합성을 이슈 리포트 정보를 토대로 유지하려고 했으나, 이슈 리포트에 올라오는 잘못된 정보로 파생되는 휴먼 에러를 피할 순 없었다. 

또한, 데이터베이스의 경우에는 개발 파트는 환경 구축에 편의성과 시간을 단축하고자, 파트 내에서 Vendor별로 지정된 데이터베이스를 공유해서 사용했다. 이로 인해서 인터페이스 정의가 겹치거나 설정이 덮어쓰는 경우가 발생해 인지하지 못하는 경우가 종종 발생했다.
## 문제 정의
+ 환경 불일치로 발생되는 이슈 재연 불가 현상
	+ 각 파트에서 프레임워크가 동작되는 환경이 서로 상이하여 동일한 인터페이스임에도 이슈가 재연이 안되는 현상이 발생 됨, 이 경우 이슈 대응 시간이 크게 지체
+ 이슈 리포트 환경 정보의 대한 휴먼 에러
	+ 환경 불일치를 막기 위해서 환경 정보에 대한 정합성을 유지하려고 했으나, 이슈 리포트가 사람이 작성하기에 휴먼 에러가 발생
+ 비효율적인 환경 전환
	+ 이슈 대응 시 다른 이슈나 긴급 이슈에 대한 분석 요청이 발생할 경우 환경을 다시 설정하는 비효율적 환경, 반복적인 환경 전환은 예기치 못한 에러 발생과 분석 효율성 감소

## 해결 과정
이슈 재연 불가 현상과 환경 정보 정합성을 유지하기 위해서 환경을 구축하는데 인적인 요소를 최소화하고, 이슈 담당자 간 독립된 환경을 구성해 충돌로 발생되는 문제를 방지했다. 그리고 비효율적인 환경 전환 문제를 해결하기 위해서 이슈 간 환경을 쉽게 설정할 수 있고 변경할 수 있도록 하는 Kubernetes 자동 배포 API를 개발했다.

자동 배포 API는 설계는 크게 아래 3개의 주요 서비스로 기반으로 구현했다. 
+ Issue Configuration Service
	+ 사이트 또는 이슈 간 실행되는 Build 버전이나 Java 파라미터 값을 상이하기에 쉽게 조정할 수 있는 서비스
	+ 이슈 대응에 필요한 환경 정보를(환경변수 및 JAVA 파라미터) 설정하는 서비스를 담당한다. ID 값을 기반으로 생성될 환경의 독립성을 보장하고 필요한 JDK 버전 정보와 Clone Repository 선정하고, 추가적으로는 프로젝트의 빌드 형식이나 실행된 주소 또한 설정할 수 있다. 본 서비스는 API 의 Gateway 역할을 담당하며 요청 정보를 기반으로 실행의 주체가 될 엔티티 'Issue' 생성하고 테이블의 INSERT 역할
+ Version Control Service
	+ 프레임워크가 저장된 Repository에서 clone 하거나 Build 버전에 맞춰 checkout / fetch 기능
	+ 'Issue' 엔티티 설정 값을 기반으로 Local Working Directory에 Repository를 Clone 하여 이슈에 이용될 프로젝트를 생성한다. 만약 브랜치 변경이나 업데이트 API가 호출될 경우 생성된 프로젝트에 checkout / fetch 명령어 수행을 담당하는 역할
+ Kubernetes Service
	+ 각 Build 버전 별로 Kubernetes 환경에 배포 기능과 프로젝트에 연동되는 JDK와 데이터베이스를 기반으로 Docker 파일 빌드 및 생성 기능
	+ 'Issue' 엔티티 설정 값 중 JDK 버전과 Java Project Build Type 을 기반으로 Docker File을 Code-generation로 생성 한 후 Kubectl 을 통해서 Cloud 환경에 배포 역할

![[Pasted image 20240910142105.png]]
'Version Control Service' 과 'Kubernetes Service'는 단순 API 작성 된 경우 Repository의 크기가 커지게 되면서 타임아웃을 발생시켜, 중앙 Message Queue를 배치해 MSA와 비동기식 이벤트 처리방식 구조적으로 변경해 구현했다. 

![[Pasted image 20240909173408.png]]
'Version Contorl Service'에 의 경우에는 clone / fetch / checkout 명령어를 수행할 수 있도록 처음에는 ProcessBuilder를 통해서 curl 명령어를 호출하여 Git 명령어를 Local Working Directory에서 수행토록 했다. 하지만 curl 명령어 구현 방식은 서비스 로직에 가독성 및 에러 처리가 까다로워 Jgit 사용하여 재구현했다. 정상적으로 Git 명령어가 수행될 경우 'Kubernetes Service'로 다음 이벤트를 처리할 수 있도록 'Kube Message'의 헤더에 Local Working Directory 경로를 헤더에 설정한 후 Queue에 Message를 등록한다. 그리고 Issue 엔티티의 상태를 SUCCEED_CLONE 으로 변경하여 전체 이벤트 상태를 알 수 있도록 했다.

![[Pasted image 20240909173403.png]]
'Kubernetes Service'는 전달 받은 Message의 Header에 있는 Local Working Directory 경로에 접근해 Code-generation 서비스를 이용해서 Docker 파일을 빌드했다. 하지만 초기 개발에서 FreeMarker를 이용해 DockerFile은 만들 경우 프로젝트 별로 Docker 파일을 생성 과정을 거쳐, 생성된 Docker 파일과 프로젝트 파일을 Build해 Container 이미지로 만든 후 Kubernetes 환경에 밀어 넣어야했다. 이렇듯 최종 Container 이미지 생성까지 많은 프로세스가 발생하고 서비스 개발인 아닌 FreeMarker 를 작성하는데 더 많은 시간이 소모되었다.

그래서 구글의 jib를 활용해서 자바 앱을 컨테이너화를 하도록 변경했다. 변경된 서비스는 자바 프로젝트의 Groovy Gradle, Kotlin Gradle 또는 Maven 에 jib 코드를 주입하여 명령어를 실행 시켜 경우, 프로젝트를 Container Image 변환 후 자동적으로 Container 업로드 되도록 구성했다.

그리고 Deployment API가 호출될 경우 업로드된 Container image를 Issue 엔티티 값을 기반으로 Kubernetes 환경 내에서 namepsace 와 pod 그리고 service를 만들어 배포한 후 외부 접속 가능한 주소 정보를 반환하도록 했다.

## 결과
Kubernetes 테스트베드 자동 구축 API 서버를 개발해 파트 내에서 시범 운행한 결과
* 이슈를 대응하기 위해서 환경을 손쉽게 생성하고 제거 가능하도록 개선했고, 특히 이슈 별 독립된 환경으로 스위칭 가능 하도록 개발해 이슈 대응 시간 줄일 수 있었음
지속적으로 사용하면서 개선한 방안들을 찾고 안정화 된다면 QA 파트에 제공하여 이슈 대응 속도를 현저히 감소할 수 있을 것으로 기대됨

# 'AnyLink 7' 프레임워크 문제점 개선한 설계 및 개발
(주)TmaxSoft, Interface Core 파트 - 연구원
2024.01 ~ 2024.06
## 설계 목적
'AnyLink 7'의 경우에 String 과 BLOB 자료형으로 구성된 각 'SYS_ID' 와 'CONTENTS' 두 개의 컬럼으로 비정형 데이터 저장 방식을 채용 후 Key-Value 구성하여 프레임워크에 필요한 자원을 XML또는 JSON, Byte 형식으로 변환해 저장 및 운영되도록 구성되어있었다. 

![[Pasted image 20240906180848.png]]

본 방식을 채용한 프레임워크는 단순히 직렬화 된 데이터를 'CONTENTS' 컬럼에 저장만 한다면 손쉽게 고객의 요구되는 설정 값과 요구 사항에 대해서 대응할 수 있기 때문에, 역직렬화 될 자바 클래스 객체만 잘 관리한다면 고객의 인터페이스의 요구 사항에 대해서 추가적인 데이터베이스 작업이나 스키마 변경에 영향을 받지 않기에 주요 비즈니스 로직을 의존성 독립할 수 있어 좋은 유연성과 확장성을 보장할 수 있다.

이 구조로 인터페이스 프레임워크는 손 쉽게 고객 별 요구 사항과 추가적인 인터페이스 기능들을 점차 유연하게 확대되어 오면서 운영되어왔다. 그 결과 현재는 Endpoint 또는 Interface Transaction에 대해서 설정할 수 있는  기능 옵션을 100 ~ 180 개를 지원해 타사 제품과 달리 넓은 편의 기능을 지원하는 프레임워크가 될 수 있었다. 하지만, 이 결과는 확장 가능성에 대해서 높은 효과 확장성을 보장했다고 말할 수 있지만 이면으로는 데이터가 무분별하게 확대되고 비즈니스 로직의 객체가 비대 해져 코드 레벨에 가독성과 유지 보수성을 저하시켰다. 이 결과로 코드 레벨에서 리소스 간의 관계 파악이 어려워 인터페이스 배포 전 유효성 검사를 완벽하게 수행하지 못했다.

장기간 제품이 운영되면서 이 문제점들은 점점 대두되며 이슈 발생률과 대응 시간에 악영향을 미치게 됬다. 실제로 이슈 대응과 신규 기능 개발 업무를 약 2년 간 맡아오며 이슈들은 공통적으로 정상적인 인터페이스 배포 및 실행이 어려우니 분석을 요청하거나 실행 할 수 있게 새로운 기능을 만들어 달라는 것이다. 왜냐하면, 장기간 운영과 신규 기능 추가로 관리해야 하는 리소스의 크기와 수는 점진적으로 커졌음에도 불구하고 리소스 유효성을 보장할 수 없어 온전히 사용자의 설정 값에 인터페이스의 배포 빛 실행 결과가 도출되었다. 

이러한 기현상이 반복되면서 개발 파트는 코드 분석보단 데이터베이스 저장된 필드 값을 비즈니스 로직에 디버깅 하면서 가이드 문서를 작성하는데 업무 시간을 소비하게 됬다. 게다가, 모든 데이터가 Key-Value 방식으로 저장된 방식은 신규 기능을 만드는데도 악영향으로 작용되었다. 필터링, 검색 기능 같이 편의성 개선을 위한 서비스를 제공하기 위해선 반드시 전체 데이터를 직렬화 한 후 비즈니스 로직에 필요한 필드만 가져와서 구현해야만 했으며, 이 직렬화 과정은 관리되는 자원이 많으면 많아질수록 서비스의 성능 저하 및 본 구조에서 구현을 위한 역정규화를 유발하는 결과를 초래했다.

## 문제 정의
+ 비즈니스 로직의 가독성과 유지보수 저하
	+ 직렬화된 데이터로 인해서 리소스 간의 관계 파악이 이루어지지 않고, Application 코드 레벨에서 가독성이 떨어져 코드 분석에 소요되는 시간이 증가
+ 성능 및 신규 기능 대응 저하
	+ 모든 데이터의 직렬화 과정이 요구되어 전체적인 성능 저하가 발생됨, 신규 기능 구현에 필요한 필드를 추출하는 과정으로 역정규화 발생함
+ 운영 효율성 저하
	+ 각 사이트 별 요구 사항에 맞춘 기능 확장으로 리소스가 비대해져 관리가 복잡해져, 이슈 발생 시 통합 디버깅이 요구되어 이슈 대응 시간이 증가

## 해결 과정
이슈 대응 시간을 감소와 신속한 원인 파악을 위해서 비즈니스 로직에 리소스 관계와 트랜잭션 동작에 대한 흐름을 파악하기 위해서 비정형 데이터 저장 방식을 지양하고 테이블 관계를 비즈니스 로직에 맞춰 명확하게 정의하기 위해서 ORM을 적극적으로 활용해 프로젝트를 구성했다. 

![[Pasted image 20240909114021.png]]

ORM을 활용해 의도한 대로 테이블을 구성하기 위해 Spring Data JPA 활용해 리소스를 Entity로 만들기로 했다. 본 과정을 위해서 기존 비정형 데이터 방식으로 저장된 리소스를 정규화 통해서 관계를 명확하게 재구성하고, GROUP 에서 GROUP을 가지는 순환 참조를 구성하고 ENDPOINT 가 설정된 프로토콜(FTP,HTTP,TCP 등)과 방향(Outbound, Inbound, Both) 에 따라서 설정 값을 상이 하다는 점을 고려해 개별적으로 구성했다. 최종적으로 Entity 수가 기존보다 증가했지만 각 리소스간의 관계를 명확하게 표현하고 각 데이터를 스키마에 맞춰 테이블로 나누어 역정규화 된 데이터를 모두 삭제했으며, 큰 BLOB 데이터를 Marshal / UnMarahal 과정을 삭제할 수 있었다.

여기에 데이터베이스의 외래키와 참조 무결성을 확실히 보장하기 위해@OneToMany 와 @ManyToOne 같은 연관관계 매핑 어노테이션을 이용해 연관 관계를 도입했다. 이것으로 리소스 관계가 명확히 데이터 베이스에서도 표현되고 Application 객체 입장에서는 상위 하위 객체 데이터를 쉽게 가져올 수 있었다. 이로써 객체는 관계성 및 외래키에 대해서 보장할 수 있게 되어 비즈니스 로직에 집중할 수 있게 되면서 코드를 쉽게 구현할 수 있게 되어 코드가 간결성과 가독성 또한 확보할 수 있게 되었다.

```java
//양방향 매핑
@Entity  
@Getter  
@Table(name = "ADAPATER")  
public class Adater { 
	@Id @GeneratedValue(strategy = GenerationType.IDENTITY)  
	@Column(name = "ADAPTER_ID", updatable = false, nullable = false)  
	private Long id;  
	  
	@Column(name = "NAME", length = 32, nullable = false)  
	private String name;  
	  
	@Column(name = "PROTOCOL", nullable = false)  
	@Enumerated(EnumType.STRING)  
	private Protocol protocol;  
	  
	@Column(name = "DESCRIPTION")  
	private String description;

	@OneToMany(mappedBy = "adapter", cascade = CascadeType.ALL, orphanRemoval = true)
	private List<EndpointGroup> groups;

	public void addGroup(EndpointGroup group) {
		groups.add(group); 
		group.setAdapter(this);
	}
	
	public void removeGroup(EndpointGroup group) {
		groups.remove(group);
		group.setAdapter(null);
	}
	//생략 
}

@Entity  
@Getter  
@Table(name = "GROUP")  
public class EndpointGroup{  
    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)  
    @Column(name = "GROUP_ID")  
    private Long id;  
  
    @Column(name = "NAME", length = 32 , nullable = false)  
    private String name;  
  
    @Column(name = "ROUTING_TYPE", nullable = false)  
    @Enumerated(EnumType.STRING)  
    private RoutingType routingType;  
  
    @ManyToOne  
    @JoinColumn(name="ADATPER_ID",  nullable = false)  
    private Adapter adapter;  
  
    @ManyToOne(fetch = FetchType.LAZY)  
    @JoinColumn(name="PARENT", referencedColumnName = "GROUP_ID")  
    private EndpointGroup parent; 

	public void setAdapter(Adapter adapter) {
		this.adapter = adapter;
	}
	//생략 
  }
```

하지만 양방향 연관관계 매핑 사용 시 관계를 관리 해야 하는 코드가 Entity 내에 추가되고 비즈니스 로직 코드 작성 시 연관 관계를 상시 관리 해주어야 정상적으로 데이터가 저장되거나 개발자가 의도치 않은 쿼리가 발생되는 문제가 있다. 이 문제로 양방향 관계 매핑은 비즈니스 로직 구현을 위해 서비스를 구현하는데 있어서 Application code level 보다 연관 관계 매핑에 집중 해야하는 문제가 발생했고, 복잡한 비즈니스 로직 구현을 위해서 리소스별 서비스를 호출하는데 있어 트랜잭션의 범위가 커지는 현상이 발생했다. 오히려 편의성을 챙기려다 의도치 않은 쪽으로 코드의 가독성이 망가진다고 판단되어 양방향 관계를 모두 제거했다.

양방향 매핑을 사용하지 않고 한 쪽 객체에만 연관 관계를 유지할 수 있도록 변경해 관계 코드를 최소화하고, 개발자가 집중해야 하는 객체를 줄임으로써 오로지 비즈니스 로직을 위한 서비스 구현에 신경쓸 수 있도록 양방향 매핑을 모두 단방향 매핑으로 변경했다. 변경함으로써 엔티티간 관계를 위한 코드가 mappedBy 삭제되며 두 개의 관계로 맺어진 객체가 하나의 관계로 맺어져 결합도를 감소시켰다. 

이 선택으로 복잡한 비즈니스 로직이 요구되는 API를 작성하거나 프로토콜에 따른 'Adapter' 또는 방향성에 따른 'Endpoint' 서비스를 정의할 때 관계가 맺어진 객체가 없어짐으로써 본 객체만 신경쓰기 때문에 기능의 확장성 및 유연성 그리고 양방향에 비해서 하나의 객체에만 트랜잭션을 정의하기에 범위를 축소 할 수 있었다.

```java
//단방향 매핑
@Entity  
@Getter  
@Table(name = "ADAPATER")  
public class Adater { 
	@Id @GeneratedValue(strategy = GenerationType.IDENTITY)  
	@Column(name = "ADAPTER_ID", updatable = false, nullable = false)  
	private Long id;  
	  
	@Column(name = "NAME", length = 32, nullable = false)  
	private String name;  
	  
	@Column(name = "PROTOCOL", nullable = false)  
	@Enumerated(EnumType.STRING)  
	private Protocol protocol;  
	  
	@Column(name = "DESCRIPTION")  
	private String description;
	
	//생략
}

@Entity  
@Getter  
@Table(name = "GROUP")  
public class EndpointGroup{  
    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)  
    @Column(name = "GROUP_ID")  
    private Long id;  
  
    @Column(name = "NAME", length = 32 , nullable = false)  
    private String name;  
  
    @Column(name = "ROUTING_TYPE", nullable = false)  
    @Enumerated(EnumType.STRING)  
    private RoutingType routingType;  
  
    @ManyToOne  
    @JoinColumn(name="ADATPER_ID",  nullable = false)  
    private Adapter adapter;  
  
    @ManyToOne(fetch = FetchType.LAZY)  
    @JoinColumn(name="PARENT", referencedColumnName = "GROUP_ID")  
    private EndpointGroup parent;  
	//생략 
  }
```


하지만, 단방향 매핑은 복합적 리소스 사용을 요구하는 API 구현 시 객체 지향적 구현 보다는 데이터베이스에 중심적으로 서비스가 구현되는 문제를 유발했다. 개발된 예로 전체 인터페이스 스켈레톤을 한 번에 정의할 수 있는 기능을 제공하게 될 경우, 외래키를 고려해서 순차적으로 데이터베이스에 INSERT 한 후 다음 하위 리소스를 INSERT를 해야만하는 등 객체가 단순 데이터베이스의 값을 지정하는 용도로만 사용되는 문제가 발생했다.

이 구조적 설계는 비즈니스 로직에 리소스에 대한 관계성은 명확하게 알 수 있지만 확장성과 유연성을 고려하지 못하는 부분이 발생했다고 볼 수 있다. 그리고 운영 파트에서는 수작업으로 데이터를 변경하거나, 각 사이트에서 외래키를 제한하는 요건이 간혈적으로 요청된다고 한다. '외래키 사용하지 않고 구현을 부탁한다' 요청을 해했다. 해당 사항을 수용하기 위해서 Spring data JPA 연관 관계 사용은 위 요구 사항을 수행할 수 없었다. 따라서, 연관 관계를 모두 제거해 데이터베이스 상 외래키를 생성하지 않으며 프레임워크내 비즈니스 로직이 데이터베이스 의존적이지 않고 오로지 객체중심적으로 서비스를 개발할 수 있도록하며 Application 레벨에서 무결성을 유지하도록 주의할 수 있는 설계를 해야했다. 

모든 요구사항을 중점적으로 고려했을 때 객체의 고유 값(=ID)을 간접적으로 참조하는 방식으로 새롭게 구현했으며, 해당 방식으로 객체의 구성은 연관 관계보다 결합도는 더 느슨해져 사이트의 새로운 기능에 대한 요청도 구현에 제약이 없기에 기획과 개발자가 의도한 방향으로 자유롭게 API를 구현할 수 있게됬다.
```java
//단방향 매핑
@Entity  
@Getter  
@Table(name = "ADAPATER")  
public class Adater { 
	@Id @GeneratedValue(strategy = GenerationType.IDENTITY)  
	@Column(name = "ADAPTER_ID", updatable = false, nullable = false)  
	private Long id;  
	  
	@Column(name = "NAME", length = 32, nullable = false)  
	private String name;  
	  
	@Column(name = "PROTOCOL", nullable = false)  
	@Enumerated(EnumType.STRING)  
	private Protocol protocol;  
	  
	@Column(name = "DESCRIPTION")  
	private String description;
	
	//생략
}

@Entity  
@Getter  
@Table(name = "GROUP")  
public class EndpointGroup{  
    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)  
    @Column(name = "GROUP_ID")  
    private Long id;  
  
    @Column(name = "NAME", length = 32 , nullable = false)  
    private String name;  
  
    @Column(name = "ROUTING_TYPE", nullable = false)  
    @Enumerated(EnumType.STRING)  
    private RoutingType routingType;  
   
    @Column(name="ADATPER_ID",  nullable = false)  
    private Long adapterId;  
  
    @Column(name="PARENT")  
    private Long parentId;  
	//생략 
  }
```

## 결과
앞 서 정의된 문제를 해결하기 위해서 총 3번의 개발 및 설계를 진행할 수 있었고, 각 방식마다 결론들을 도출해낼 수 있었습니다.

+ 비즈니스 로직 중심의 설계를 위해서 ORM을 적극적으로 활용해 리소스 간의 관계를 명확히 정의하고 Spring data JPA의 연관 관계 매핑 방식을 도입해 데이터베이스와 Application 간의 일관성을 확보하려했다. 하지만 양방향 매핑의 편의성 대비 비즈니스 로직보다 연관 관계 정의에 대한 복잡성이 관계 관리에 집중하게 되는 문제를 유발했다. 이를 해결하기 위해서 단방향 매핑으로 변경하여 불필요한 관계를 최소화하고 개발자가 비즈니스 로직에 집중할 수 있게 했다.
+ 단방향 매핑으로 객체 간의 결합도를 낮추고 트랙잭션 범위를 축소하여 성능 및 코드 가독성 측면에서 개선이 되었지만, 외래키 의존성으로 데이터베이스 중심적 서비스 구현이 되면서 객체 지향적 구현을 저해시키는 현상이 발생됬다. 이 현상은 특히 복합적인 리소스가 사용되는 API 구현 시 오히려 유연성과 확장성을 감소 시키는 요소가 되었다.
+ 개발적 운영적으로 외래키 의존성을 해결하기 위해서 연관 관계 매핑을 모두 제거하고 객체의 ID 를 통해서 간접적으로 참조하는 방식을 도입해 데이터베이스에 의존적이지 않고 Application 레벨에서 무결성을 관리하는 설계로 전환하여 유연성과 확장성을 보장했다.
+ 최종적으로 각 객체의 ID를 통해서 결합도를 낮추고 비즈니스 로직 분석만으로도 리소스 간의 관계성을 파악할 수 있고 신규 기능 개발 시 외부 제약을 제거해 사이트 별 요구 사항에 맞춰서 신속하게 대응할 수 있는 유연한 설계를 구축했다.
+ 간접 ID 참조 방식을 통해서 데이터베이스 로직을 담고있는 Service Layer 와 유효성 체크 및 API의 전체 흐름을 담당하는 API Layer 명확히 분리할 수 있어, 데이터베이스와 API 문제인지 명확히 구분할 수 있게 됨

다만 과거의 프레임워크 설계보다 개발자가 전체적인 흐름을 인지하고 관심을 가지며 개발을 해야하며, 트랙잰션 동안 객체 저장에 실패 시 자동으로 롤백되는 로직은 직접 구현하여야 하는 숙제가 남음

